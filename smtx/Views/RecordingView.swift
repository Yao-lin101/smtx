import SwiftUI
import AVFoundation
import CoreData

struct RecordingView: View {
    let template: Template
    @Environment(\.dismiss) private var dismiss
    @StateObject private var audioRecorder = AudioRecorder()
    @State private var currentTime: Double = 0
    @State private var currentItem: TimelineItem?
    @State private var currentImage: UIImage?
    @State private var overlayHeight: CGFloat = 0
    @State private var timer: Timer?
    @State private var isRecordingStopped = false
    @State private var isPreviewMode = false
    @State private var recordedDuration: Double = 0
    @State private var previewPlayer: AVAudioPlayer?
    
    private var progress: Double {
        template.totalDuration > 0 ? currentTime / template.totalDuration : 0
    }
    
    var body: some View {
        VStack(spacing: 0) {
            // é¡¶éƒ¨å†…å®¹åŒºåŸŸ
            VStack(spacing: 20) {
                // å›¾ç‰‡åŒºåŸŸ
                ZStack {
                    if let image = currentImage {
                        Image(uiImage: image)
                            .resizable()
                            .scaledToFit()
                            .clipShape(RoundedRectangle(cornerRadius: 12))
                    } else {
                        RoundedRectangle(cornerRadius: 12)
                            .fill(Color.secondary.opacity(0.2))
                            .overlay {
                                Image(systemName: "photo")
                                    .font(.largeTitle)
                                    .foregroundColor(.secondary)
                            }
                    }
                }
                .frame(height: 200)
                
                // å°è¯åŒºåŸŸ
                ZStack {
                    if let script = currentItem?.script {
                        Text(script)
                            .font(.body)
                            .multilineTextAlignment(.center)
                    } else {
                        Text("æ— å°è¯")
                            .font(.body)
                            .foregroundColor(.secondary)
                    }
                }
                .frame(height: 60)
                .padding(.horizontal)
                
                // è¿›åº¦æ¡
                VStack(spacing: 4) {
                    GeometryReader { geometry in
                        ZStack(alignment: .leading) {
                            // èƒŒæ™¯æ¡
                            RoundedRectangle(cornerRadius: 2)
                                .fill(Color.secondary.opacity(0.2))
                                .frame(height: 4)
                            
                            // è¿›åº¦æ¡
                            RoundedRectangle(cornerRadius: 2)
                                .fill(Color.accentColor)
                                .frame(width: geometry.size.width * progress, height: 4)
                        }
                    }
                    .frame(height: 4)
                    
                    // æ—¶é—´æ˜¾ç¤º
                    HStack {
                        Text(formatTime(currentTime))
                        Spacer()
                        Text(formatTime(template.totalDuration))
                    }
                    .font(.caption.monospacedDigit())
                    .foregroundColor(.secondary)
                }
                .padding(.horizontal)
            }
            .padding(.vertical)
            
            Spacer()
            
            // åº•éƒ¨å½•éŸ³åŒºåŸŸ
            VStack(spacing: 20) {
                // ç¤ºæ³¢å›¾åŒºåŸŸï¼ˆå½•éŸ³æ—¶æ˜¾ç¤ºï¼‰
                if audioRecorder.isRecording {
                    WaveformView(levels: audioRecorder.audioLevels)
                        .frame(height: 100)
                        .padding(.horizontal, 4)
                        .background(
                            RoundedRectangle(cornerRadius: 16)
                                .fill(Color.black.opacity(0.08))
                        )
                        .padding(.horizontal, 8)
                }
                
                // æ§åˆ¶æŒ‰é’®
                HStack(spacing: 40) {
                    if isPreviewMode {
                        // è¿”å›æŒ‰é’®
                        Button {
                            dismiss()
                        } label: {
                            Image(systemName: "xmark.circle.fill")
                                .font(.title)
                                .foregroundColor(.secondary)
                        }
                        
                        // æ’­æ”¾/æš‚åœæŒ‰é’®
                        Button {
                            if let player = previewPlayer {
                                if player.isPlaying {
                                    pausePreview()
                                } else {
                                    startPreview()
                                }
                            }
                        } label: {
                            Image(systemName: previewPlayer?.isPlaying == true ? "pause.circle.fill" : "play.circle.fill")
                                .font(.system(size: 80))
                                .foregroundColor(.accentColor)
                        }
                        
                        // å®ŒæˆæŒ‰é’®
                        Button {
                            saveRecordingAndDismiss()
                        } label: {
                            Image(systemName: "checkmark.circle.fill")
                                .font(.title)
                                .foregroundColor(.green)
                        }
                    } else {
                        // å½•éŸ³æŒ‰é’®
                        Button(action: audioRecorder.isRecording ? stopRecording : startRecording) {
                            Circle()
                                .fill(audioRecorder.isRecording ? .red : .accentColor)
                                .frame(width: 80, height: 80)
                                .overlay {
                                    RoundedRectangle(cornerRadius: audioRecorder.isRecording ? 4 : 40)
                                        .fill(Color.white)
                                        .frame(width: audioRecorder.isRecording ? 30 : 30,
                                             height: audioRecorder.isRecording ? 30 : 30)
                                }
                        }
                    }
                }
                .padding(.bottom, 40)
            }
        }
        .navigationBarTitleDisplayMode(.inline)
        .onAppear {
            if let firstItem = template.timelineItems?.allObjects.first as? TimelineItem {
                currentItem = firstItem
                initializeFirstImage()
            }
        }
        .onDisappear {
            stopRecording()
            stopPreview()
        }
    }
    
    private func startRecording() {
        print("ğŸ™ï¸ Starting recording...")
        
        isRecordingStopped = false
        
        // åˆ›å»ºå½•éŸ³æ–‡ä»¶URL
        guard let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first else {
            print("âŒ Failed to get documents directory")
            return
        }
        let recordingName = "recording_\(Date().timeIntervalSince1970).m4a"
        let recordingURL = documentsPath.appendingPathComponent(recordingName)
        print("ğŸ“ Recording will be saved to: \(recordingURL.path)")
        
        audioRecorder.startRecording(url: recordingURL)
        overlayHeight = 200
        
        currentTime = 0
        
        timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
            currentTime += 0.1
            updateTimelineContent()
            
            if currentTime >= template.totalDuration {
                stopRecording()
            }
        }
    }
    
    private func stopRecording() {
        // é¿å…é‡å¤è°ƒç”¨
        if isRecordingStopped {
            return
        }
        isRecordingStopped = true
        
        print("ğŸ›‘ Stopping recording...")
        
        // åœæ­¢å½•éŸ³å’Œæ—¶é—´è½´æ’­æ”¾
        audioRecorder.stopRecording()
        overlayHeight = 0
        
        // åœæ­¢è®¡æ—¶å™¨
        timer?.invalidate()
        timer = nil
        
        // å¦‚æœæ²¡æœ‰å®é™…å½•éŸ³ï¼Œç›´æ¥è¿”å›
        guard let recordingURL = audioRecorder.recordingURL else {
            return
        }
        
        // ä¿å­˜å½•éŸ³æ—¶é•¿
        recordedDuration = currentTime
        
        // é…ç½®éŸ³é¢‘ä¼šè¯ä¸ºæ’­æ”¾æ¨¡å¼
        do {
            try AVAudioSession.sharedInstance().setCategory(.playback)
            try AVAudioSession.sharedInstance().setActive(true)
        } catch {
            print("âŒ Failed to set audio session category: \(error)")
        }
        
        // å‡†å¤‡é¢„è§ˆ
        do {
            previewPlayer = try AVAudioPlayer(contentsOf: recordingURL)
            isPreviewMode = true
            currentTime = 0
            if let firstItem = template.timelineItems?.allObjects.first as? TimelineItem {
                updateContent(for: firstItem)
            }
        } catch {
            print("âŒ Failed to create preview player: \(error)")
        }
    }
    
    private func updateTimelineContent() {
        // æŸ¥æ‰¾å½“å‰æ—¶é—´å¯¹åº”çš„æ—¶é—´è½´é¡¹ç›®
        let currentTimeInt = Int(currentTime)
        if let items = template.timelineItems?.allObjects as? [TimelineItem],
           let currentItem = items.first(where: { Int($0.timestamp) == currentTimeInt }) {
            // æ›´æ–°å°è¯
            self.currentItem = currentItem
            
            // å¦‚æœå½“å‰é¡¹ç›®æœ‰å›¾ç‰‡ï¼Œåˆ™æ›´æ–°å›¾ç‰‡
            if let imageData = currentItem.image,
               let image = UIImage(data: imageData) {
                currentImage = image
            }
            // å¦‚æœå½“å‰é¡¹ç›®æ²¡æœ‰å›¾ç‰‡ï¼Œä¿æŒç°æœ‰å›¾ç‰‡ä¸å˜
        }
    }
    
    private func updateContent(for item: TimelineItem) {
        // åªæœ‰åœ¨é¡¹ç›®å˜åŒ–æ—¶æ‰æ›´æ–°å†…å®¹
        if currentItem?.timestamp != item.timestamp {
            currentItem = item
            if let imageData = item.image,
               let image = UIImage(data: imageData) {
                currentImage = image
            }
        }
    }
    
    private func formatTime(_ time: Double) -> String {
        let minutes = Int(time) / 60
        let seconds = Int(time) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
    
    private func startPreview() {
        guard let player = previewPlayer else { return }
        
        do {
            try AVAudioSession.sharedInstance().setActive(true)
        } catch {
            print("âŒ Failed to activate audio session: \(error)")
        }
        
        currentTime = 0
        if let items = template.timelineItems?.allObjects as? [TimelineItem],
           let firstItem = items.first {
            updateContent(for: firstItem)
        }
        
        player.play()
        
        timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
            currentTime = player.currentTime
            updateTimelineContent()
            
            if currentTime >= recordedDuration {
                stopPreview()
            }
        }
    }
    
    private func pausePreview() {
        previewPlayer?.pause()
        timer?.invalidate()
        timer = nil
    }
    
    private func stopPreview() {
        previewPlayer?.stop()
        timer?.invalidate()
        timer = nil
        currentTime = 0
        if let firstItem = template.timelineItems?.allObjects.first as? TimelineItem {
            updateContent(for: firstItem)
        }
    }
    
    private func saveRecordingAndDismiss() {
        do {
            // å°†å½•éŸ³æ–‡ä»¶è½¬æ¢ä¸ºæ•°æ®
            guard let sourceURL = audioRecorder.recordingURL,
                  let audioData = try? Data(contentsOf: sourceURL) else {
                print("âŒ Failed to get recording data")
                return
            }
            
            // ä¿å­˜å½•éŸ³è®°å½•
            guard let templateId = template.id else {
                print("âŒ Template ID is nil")
                return
            }
            
            let recordId = try TemplateStorage.shared.saveRecord(
                templateId: templateId,
                duration: recordedDuration,
                audioData: audioData
            )
            
            print("âœ… Recording saved with ID: \(recordId)")
            
            // å‘é€å½•éŸ³å®Œæˆé€šçŸ¥
            NotificationCenter.default.post(
                name: .recordingFinished,
                object: nil,
                userInfo: ["templateId": templateId]
            )
            
            // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿é€šçŸ¥è¢«å¤„ç†
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
                dismiss()
            }
            
            // åˆ é™¤ä¸´æ—¶å½•éŸ³æ–‡ä»¶
            try? FileManager.default.removeItem(at: sourceURL)
            
        } catch {
            print("âŒ Failed to save recording: \(error)")
        }
    }
    
    private func initializeFirstImage() {
        guard let items = template.timelineItems?.allObjects as? [TimelineItem] else { return }
        
        // æŸ¥æ‰¾ç¬¬ä¸€ä¸ªåŒ…å«å›¾ç‰‡çš„é¡¹ç›®
        if let firstItemWithImage = items.first(where: { $0.image != nil }),
           let imageData = firstItemWithImage.image,
           let image = UIImage(data: imageData) {
            currentImage = image
        }
    }
} 