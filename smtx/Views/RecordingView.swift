import SwiftUI
import AVFoundation
import CoreData

struct RecordingView: View {
    let template: Template
    let recordId: String?
    @Environment(\.dismiss) private var dismiss
    @StateObject private var audioRecorder = AudioRecorder()
    @State private var currentTime: Double = 0
    @State private var currentItem: TimelineItem?
    @State private var currentImage: UIImage?
    @State private var overlayHeight: CGFloat = 0
    @State private var timer: Timer?
    @State private var isRecordingStopped = false
    @State private var isPreviewMode = false
    @State private var recordedDuration: Double = 0
    @State private var previewPlayer: AVAudioPlayer?
    
    private var progress: Double {
        template.totalDuration > 0 ? currentTime / template.totalDuration : 0
    }
    
    var body: some View {
        VStack(spacing: 0) {
            // é¡¶éƒ¨å†…å®¹åŒºåŸŸ
            VStack(spacing: 20) {
                // å›¾ç‰‡åŒºåŸŸ
                ZStack {
                    if let image = currentImage {
                        Image(uiImage: image)
                            .resizable()
                            .scaledToFit()
                            .clipShape(RoundedRectangle(cornerRadius: 12))
                    } else {
                        RoundedRectangle(cornerRadius: 12)
                            .fill(Color.secondary.opacity(0.2))
                            .overlay {
                                Image(systemName: "photo")
                                    .font(.largeTitle)
                                    .foregroundColor(.secondary)
                            }
                    }
                }
                .frame(height: 200)
                
                // å°è¯åŒºåŸŸ
                ZStack {
                    if let script = currentItem?.script {
                        Text(script)
                            .font(.body)
                            .multilineTextAlignment(.center)
                    } else {
                        Text("æ— å°è¯")
                            .font(.body)
                            .foregroundColor(.secondary)
                    }
                }
                .frame(height: 60)
                .padding(.horizontal)
                
                // è¿›åº¦æ¡
                VStack(spacing: 4) {
                    GeometryReader { geometry in
                        ZStack(alignment: .leading) {
                            // 
                            RoundedRectangle(cornerRadius: 2)
                                .fill(Color.secondary.opacity(0.2))
                                .frame(height: 4)
                            
                            // è¿›åº¦æ¡
                            RoundedRectangle(cornerRadius: 2)
                                .fill(Color.accentColor)
                                .frame(width: geometry.size.width * progress, height: 4)
                        }
                    }
                    .frame(height: 4)
                    
                    // æ—¶é—´æ˜¾ç¤º
                    HStack {
                        Text(formatTime(currentTime))
                        Spacer()
                        Text(formatTime(template.totalDuration))
                    }
                    .font(.caption.monospacedDigit())
                    .foregroundColor(.secondary)
                }
                .padding(.horizontal)
            }
            .padding(.vertical)
            
            Spacer()
            
            // åº•éƒ¨æ§åˆ¶åŒºåŸŸ
            VStack(spacing: 20) {
                // ç¤ºæ³¢å›¾åŒºåŸŸ (å½•éŸ³å’Œé¢„è§ˆéƒ½æ˜¾ç¤º)
                WaveformView(levels: audioRecorder.audioLevels)
                    .frame(height: 100)
                    .padding(.horizontal, 4)
                    .background(
                        RoundedRectangle(cornerRadius: 16)
                            .fill(Color.black.opacity(0.08))
                    )
                    .padding(.horizontal, 8)
                    .opacity(audioRecorder.isRecording ? 1 : 0) // åªåœ¨å½•éŸ³æ—¶æ˜¾ç¤º
                
                // æ§åˆ¶æŒ‰é’®åŒºåŸŸ
                HStack(spacing: 40) {
                    Group {
                        if isPreviewMode {
                            // é¢„è§ˆæ¨¡å¼æŒ‰é’®ç»„
                            HStack(spacing: 40) {
                                // æ³¢å½¢å›¾æŒ‰é’®
                                Button {
                                    // TODO: æ˜¾ç¤ºæ³¢å½¢å›¾
                                } label: {
                                    Image(systemName: "waveform")
                                        .font(.title)
                                        .foregroundColor(.blue)
                                }
                                
                                // åé€€15ç§’
                                Button {
                                    if let player = previewPlayer {
                                        let newTime = max(0, player.currentTime - 15)
                                        player.currentTime = newTime
                                        currentTime = newTime
                                        updateTimelineContent()
                                    }
                                } label: {
                                    Image(systemName: "gobackward.15")
                                        .font(.title)
                                }
                                
                                // æ’­æ”¾/æš‚åœæŒ‰é’®
                                Button {
                                    if let player = previewPlayer {
                                        if player.isPlaying {
                                            pausePreview()
                                        } else {
                                            startPreview()
                                        }
                                    }
                                } label: {
                                    Image(systemName: previewPlayer?.isPlaying == true ? "pause.fill" : "play.fill")
                                        .font(.system(size: 40))
                                }
                                
                                // å‰è¿›15ç§’
                                Button {
                                    if let player = previewPlayer {
                                        let newTime = min(recordedDuration, player.currentTime + 15)
                                        player.currentTime = newTime
                                        currentTime = newTime
                                        updateTimelineContent()
                                    }
                                } label: {
                                    Image(systemName: "goforward.15")
                                        .font(.title)
                                }
                                
                                // åˆ é™¤æŒ‰é’®
                                Button {
                                    // TODO: å®ç°åˆ é™¤åŠŸèƒ½
                                } label: {
                                    Image(systemName: "trash")
                                        .font(.title)
                                        .foregroundColor(.blue)
                                }
                            }
                            .transition(.asymmetric(
                                insertion: .scale(scale: 0.3)
                                    .combined(with: .opacity)
                                    .animation(.spring(response: 0.4, dampingFraction: 0.7)),
                                removal: .scale(scale: 0.3)
                                    .combined(with: .opacity)
                                    .animation(.easeOut(duration: 0.2))
                            ))
                        } else {
                            // å½•éŸ³æŒ‰é’®
                            Button(action: audioRecorder.isRecording ? stopRecording : startRecording) {
                                Circle()
                                    .fill(audioRecorder.isRecording ? .red : .accentColor)
                                    .frame(width: 80, height: 80)
                                    .overlay {
                                        RoundedRectangle(cornerRadius: audioRecorder.isRecording ? 4 : 40)
                                            .fill(Color.white)
                                            .frame(width: audioRecorder.isRecording ? 30 : 30,
                                                 height: audioRecorder.isRecording ? 30 : 30)
                                    }
                            }
                            .transition(.asymmetric(
                                insertion: .scale(scale: 0.3)
                                    .combined(with: .opacity)
                                    .animation(.spring(response: 0.4, dampingFraction: 0.7)),
                                removal: .scale(scale: 0.3)
                                    .combined(with: .opacity)
                                    .animation(.easeOut(duration: 0.2))
                            ))
                        }
                    }
                    .animation(
                        .spring(response: 0.4, dampingFraction: 0.8),
                        value: isPreviewMode
                    )
                }
                .padding(.horizontal)
            }
            .padding(.bottom, 40)
        }
        .navigationBarTitleDisplayMode(.inline)
        .onAppear {
            if let recordId = recordId {
                // å¦‚æœæœ‰ recordIdï¼ŒåŠ è½½å½•éŸ³å¹¶è¿›å…¥é¢„è§ˆæ¨¡å¼
                loadRecordingForPreview(recordId: recordId)
            } else {
                // æ²¡æœ‰ recordIdï¼Œåˆå§‹åŒ–ä¸ºå½•éŸ³æ¨¡å¼
                if let firstItem = template.timelineItems?.allObjects.first as? TimelineItem {
                    currentItem = firstItem
                    initializeFirstImage()
                }
            }
        }
        .onDisappear {
            stopRecording()
            stopPreview()
        }
    }
    
    private func startRecording() {
        print("ğŸ™ï¸ Starting recording...")
        
        isRecordingStopped = false
        
        // åˆ›å»ºå½•éŸ³æ–‡ä»¶URL
        guard let documentsPath = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first else {
            print("âŒ Failed to get documents directory")
            return
        }
        let recordingName = "recording_\(Date().timeIntervalSince1970).m4a"
        let recordingURL = documentsPath.appendingPathComponent(recordingName)
        print("ğŸ“ Recording will be saved to: \(recordingURL.path)")
        
        audioRecorder.startRecording(url: recordingURL)
        overlayHeight = 200
        
        currentTime = 0
        
        timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
            currentTime += 0.1
            updateTimelineContent()
            
            if currentTime >= template.totalDuration {
                stopRecording()
            }
        }
    }
    
    private func stopRecording() {
        // é¿å…é‡å¤è°ƒç”¨
        if isRecordingStopped {
            return
        }
        isRecordingStopped = true
        
        print("ğŸ›‘ Stopping recording...")
        
        // åœæ­¢å½•éŸ³å’Œæ—¶é—´è½´æ’­æ”¾
        audioRecorder.stopRecording()
        overlayHeight = 0
        
        // åœæ­¢è®¡æ—¶å™¨
        timer?.invalidate()
        timer = nil
        
        // å¦‚æœæ²¡æœ‰å®é™…å½•éŸ³ï¼Œç›´æ¥è¿”å›
        guard let recordingURL = audioRecorder.recordingURL else {
            return
        }
        
        // ä¿å­˜å½•éŸ³æ—¶é•¿
        recordedDuration = currentTime
        
        do {
            // å…ˆé…ç½®éŸ³é¢‘ä¼šè¯
            try AVAudioSession.sharedInstance().setCategory(.playback)
            try AVAudioSession.sharedInstance().setActive(true)
            
            // åˆ›å»ºé¢„è§ˆæ’­æ”¾å™¨
            previewPlayer = try AVAudioPlayer(contentsOf: recordingURL)
            
            // è‡ªåŠ¨ä¿å­˜å½•éŸ³
            saveRecording { success in
                if success {
                    DispatchQueue.main.async { [self] in
                        // è¿›å…¥é¢„è§ˆæ¨¡å¼
                        isPreviewMode = true
                        currentTime = 0
                        if let firstItem = template.timelineItems?.allObjects.first as? TimelineItem {
                            updateContent(for: firstItem)
                        }
                    }
                }
            }
        } catch {
            print("âŒ Failed to prepare preview: \(error)")
        }
    }
    
    private func updateTimelineContent() {
        // æŸ¥æ‰¾å½“å‰æ—¶é—´å¯¹åº”çš„æ—¶é—´è½´é¡¹ç›®
        let currentTimeInt = Int(currentTime)
        if let items = template.timelineItems?.allObjects as? [TimelineItem],
           let currentItem = items.first(where: { Int($0.timestamp) == currentTimeInt }) {
            // æ›´æ–°å°è¯
            self.currentItem = currentItem
            
            // å¦‚æœå½“å‰é¡¹ç›®æœ‰å›¾ç‰‡ï¼Œåˆ™æ›´æ–°å›¾ç‰‡
            if let imageData = currentItem.image,
               let image = UIImage(data: imageData) {
                currentImage = image
            }
            // å¦‚æœå½“å‰é¡¹ç›®æ²¡æœ‰å›¾ç‰‡ï¼Œä¿æŒç°æœ‰å›¾ç‰‡ä¸å˜
        }
    }
    
    private func updateContent(for item: TimelineItem) {
        // åªæœ‰åœ¨é¡¹ç›®å˜åŒ–æ—¶æ‰æ›´æ–°å†…å®¹
        if currentItem?.timestamp != item.timestamp {
            currentItem = item
            if let imageData = item.image,
               let image = UIImage(data: imageData) {
                currentImage = image
            }
        }
    }
    
    private func formatTime(_ time: Double) -> String {
        let minutes = Int(time) / 60
        let seconds = Int(time) % 60
        return String(format: "%d:%02d", minutes, seconds)
    }
    
    private func startPreview() {
        guard let player = previewPlayer else { return }
        
        do {
            try AVAudioSession.sharedInstance().setActive(true)
        } catch {
            print("âŒ Failed to activate audio session: \(error)")
        }
        
        currentTime = 0
        if let items = template.timelineItems?.allObjects as? [TimelineItem],
           let firstItem = items.first {
            updateContent(for: firstItem)
        }
        
        player.play()
        
        timer = Timer.scheduledTimer(withTimeInterval: 0.1, repeats: true) { _ in
            currentTime = player.currentTime
            updateTimelineContent()
            
            if currentTime >= recordedDuration {
                stopPreview()
            }
        }
    }
    
    private func pausePreview() {
        previewPlayer?.pause()
        timer?.invalidate()
        timer = nil
    }
    
    private func stopPreview() {
        previewPlayer?.stop()
        timer?.invalidate()
        timer = nil
        currentTime = 0
        if let firstItem = template.timelineItems?.allObjects.first as? TimelineItem {
            updateContent(for: firstItem)
        }
    }
    
    private func saveRecordingAndDismiss() {
        do {
            // å°†å½•éŸ³æ–‡ä»¶è½¬æ¢ä¸ºæ•°æ®
            guard let sourceURL = audioRecorder.recordingURL,
                  let audioData = try? Data(contentsOf: sourceURL) else {
                print("âŒ Failed to get recording data")
                return
            }
            
            // ä¿å­˜å½•éŸ³è®°å½•
            guard let templateId = template.id else {
                print("âŒ Template ID is nil")
                return
            }
            
            let recordId = try TemplateStorage.shared.saveRecord(
                templateId: templateId,
                duration: recordedDuration,
                audioData: audioData
            )
            
            print("âœ… Recording saved with ID: \(recordId)")
            
            // å‘é€å½•éŸ³å®Œæˆé€šçŸ¥
            NotificationCenter.default.post(
                name: .recordingFinished,
                object: nil,
                userInfo: ["templateId": templateId]
            )
            
            // ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿é€šçŸ¥è¢«å¤„ç†
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.1) {
                dismiss()
            }
            
            // åˆ é™¤ä¸´æ—¶å½•éŸ³æ–‡ä»¶
            try? FileManager.default.removeItem(at: sourceURL)
            
        } catch {
            print("âŒ Failed to save recording: \(error)")
        }
    }
    
    private func initializeFirstImage() {
        guard let items = template.timelineItems?.allObjects as? [TimelineItem] else { return }
        
        // æŸ¥æ‰¾ç¬¬ä¸€ä¸ªåŒ…å«å›¾ç‰‡çš„é¡¹ç›®
        if let firstItemWithImage = items.first(where: { $0.image != nil }),
           let imageData = firstItemWithImage.image,
           let image = UIImage(data: imageData) {
            currentImage = image
        }
    }
    
    private func loadRecordingForPreview(recordId: String) {
        if let records = template.records?.allObjects as? [Record],
           let record = records.first(where: { $0.id == recordId }),
           let audioData = record.audioData {
            do {
                // åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent("preview_\(recordId).m4a")
                try audioData.write(to: tempURL)
                
                // åˆ›å»ºæ’­æ”¾å™¨
                previewPlayer = try AVAudioPlayer(contentsOf: tempURL)
                recordedDuration = record.duration
                isPreviewMode = true
                
                // åˆå§‹åŒ–ç¬¬ä¸€å¸§å†…å®¹
                if let firstItem = template.timelineItems?.allObjects.first as? TimelineItem {
                    currentItem = firstItem
                    initializeFirstImage()
                }
                
            } catch {
                print("âŒ Failed to load recording for preview: \(error)")
            }
        }
    }
    
    private func saveRecording(completion: @escaping (Bool) -> Void) {
        do {
            guard let sourceURL = audioRecorder.recordingURL,
                  let audioData = try? Data(contentsOf: sourceURL),
                  let templateId = template.id else {
                completion(false)
                return
            }
            
            let recordId = try TemplateStorage.shared.saveRecord(
                templateId: templateId,
                duration: recordedDuration,
                audioData: audioData
            )
            
            print("âœ… Recording saved with ID: \(recordId)")
            
            // å‘é€å½•éŸ³å®Œæˆé€šçŸ¥
            NotificationCenter.default.post(
                name: .recordingFinished,
                object: nil,
                userInfo: ["templateId": templateId]
            )
            
            // åœ¨å®Œæˆå›è°ƒä¹‹åå†åˆ é™¤æºæ–‡ä»¶
            DispatchQueue.main.async {
                try? FileManager.default.removeItem(at: sourceURL)
                completion(true)
            }
        } catch {
            print("âŒ Failed to save recording: \(error)")
            completion(false)
        }
    }
} 